{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.Tensor()\n",
    "type(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For PyTorch we have: data type, device, layout\n",
    "\n",
    "The data type for each tensor must be the same for any arithmetic operation to be applied to both of them\n",
    "\n",
    "the device between each tensor must also be the same to prevent error\n",
    "\n",
    "the strided layout is the most popular and default layout so this is not changed"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(t.dtype)\n",
    "print(t.device)\n",
    "print(t.layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([1,2,3])\n",
    "type(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of these different functions for initialising a tensor object are different and the Tensor functions specifically is seen to produce a different variable type to that which was input to the numpy array\n",
    "\n",
    "deciding which of these tensor constructors to use is dependent on their methods of producing and tensor\n",
    "\n",
    "the first Tensor, is a class constructors\n",
    "\n",
    "the other three are factory functions, a factory fuction is a function which accepts particular parameter inputs and then returns a specific object output they are an OOP theory for making objects\n",
    "\n",
    "the factory functions are therefore preferred as they contain more documentation and they infer the data type of the input"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.Tensor(data)\n",
    "t2 = torch.tensor(data)\n",
    "t3 = torch.as_tensor(data)\n",
    "t4 = torch.from_numpy(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(t1)\n",
    "print(t2)\n",
    "print(t3)\n",
    "print(t4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(t1.dtype)\n",
    "print(t2.dtype)\n",
    "print(t3.dtype)\n",
    "print(t4.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here it can be seen that the Tensor constructor produces a different data type to that which is used by the the factory functions,\n",
    "\n",
    "this is because the factory functions have data inference, and the class constructor uses the default tensor data type of float32\n",
    "\n",
    "when the tensor is initialised, the data type can be specified in the factory function parameters"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(np.array([1,2,3]), dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "even though the numpy array passed through integer to the tensor, the data type was specified as float, and so that was output"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0] = 0\n",
    "data[1] = 0\n",
    "data[2] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(t1)\n",
    "print(t2)\n",
    "print(t3)\n",
    "print(t4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the first two tensors contain the original values changing the array after the fact, didnt change the tensor data\n",
    "\n",
    "the second two tensors contain the same data that is in the array after the change\n",
    "\n",
    "this change is determined to how the different objects are created under the memory the first two create a copy of the array and save it seperately\n",
    "\n",
    "the second two share the data with the numpy array\n",
    "\n",
    "given all this information it is advised to use the torch.tensor factory function in everday use, but for optimising for performance, it is advised to use the torch.as_tensor factory function as no memory copying is needed"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.eye(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.zeros(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.ones(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.rand(2,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "each of these four inbuilt PyTorch functions make it possible to produce a tensor without any data before hand"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = [\n",
    "[1,2,3],\n",
    "[4,5,6],\n",
    "[7,8,9]\n",
    "]\n",
    "\n",
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = torch.tensor(dd)\n",
    "a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[1., 1., 1., 1.],\n        [2., 2., 2., 2.],\n        [3., 3., 3., 3.]])"
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "t5 = torch.tensor([\n",
    "    [1,1,1,1],\n",
    "    [2,2,2,2],\n",
    "    [3,3,3,3]\n",
    "], dtype=torch.float32)\n",
    "t5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([3, 4])"
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "t5.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([3, 4])"
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "t5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "2"
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "len(t5.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the length of the shape object determines its rank, i.e. the number of indexes required to find a number value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor(12)"
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "torch.tensor(t5.shape).prod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "12"
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "t5.numel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "both of these operations show the number of items within the tensor, any reshaping must account for all values of the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[1., 1., 1., 1., 2., 2., 2., 2., 3., 3., 3., 3.]])"
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "t5.reshape(1,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[[1., 1., 1.],\n         [1., 2., 2.]],\n\n        [[2., 2., 3.],\n         [3., 3., 3.]]])"
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "source": [
    "t5.reshape(2,2,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this reshaping changed the rank of the tensor to a rank 3 tensor, as it now requires 3 indexes to specify a number value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[1., 1., 1., 1., 2., 2., 2., 2., 3., 3., 3., 3.]])\ntorch.Size([1, 12])\n"
    }
   ],
   "source": [
    "print(t5.reshape(1,12))\n",
    "print(t5.reshape(1,12).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([1., 1., 1., 1., 2., 2., 2., 2., 3., 3., 3., 3.])\ntorch.Size([12])\n"
    }
   ],
   "source": [
    "print(t5.reshape(1,12).squeeze())\n",
    "print(t5.reshape(1,12).squeeze().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[[1., 1., 1., 1., 2., 2., 2., 2., 3., 3., 3., 3.]]])\ntorch.Size([1, 1, 12])\n"
    }
   ],
   "source": [
    "print(t5.reshape(1,12).unsqueeze(dim=0))\n",
    "print(t5.reshape(1,12).unsqueeze(dim=0).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "squeezing the tensor removes the axes with a length of one\n",
    "\n",
    "unsqueezing adds a dimension with a length of one\n",
    "\n",
    "this is another way of reshaping the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(t):\n",
    "    t = t.reshape(1,-1)\n",
    "    t = t.squeeze()\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([1., 1., 1., 1., 2., 2., 2., 2., 3., 3., 3., 3.])"
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": [
    "flatten(t5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "flattening a tensor is the process of removing all the axes, and reducing the tensor to a one dimensional tensor.\n",
    "this is required from moving data from a convolutional layer to a fully connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = torch.tensor([\n",
    "    [1,2],\n",
    "    [3,4]\n",
    "])\n",
    "n2 = torch.tensor([\n",
    "    [5,6],\n",
    "    [7,8]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[1, 2],\n        [3, 4],\n        [5, 6],\n        [7, 8]])"
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "source": [
    "torch.cat((n1,n2), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[1, 2, 5, 6],\n        [3, 4, 7, 8]])"
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "source": [
    "torch.cat((n1,n2), dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is a Concatenating function, it enables us to increase the number of elements within the resulting tensor \n",
    "\n",
    "the first has been applied row wise \n",
    "\n",
    "the second has been applied column wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = torch.tensor([\n",
    "    [1,1,1,1],\n",
    "    [1,1,1,1],\n",
    "    [1,1,1,1],\n",
    "    [1,1,1,1]\n",
    "])\n",
    "\n",
    "a2 = torch.tensor([\n",
    "    [2,2,2,2],\n",
    "    [2,2,2,2],\n",
    "    [2,2,2,2],\n",
    "    [2,2,2,2]\n",
    "])\n",
    "\n",
    "a3 = torch.tensor([\n",
    "    [3,3,3,3],\n",
    "    [3,3,3,3],\n",
    "    [3,3,3,3],\n",
    "    [3,3,3,3]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([3, 4, 4])"
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "source": [
    "a = torch.stack((a1,a2,a3))\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[[1, 1, 1, 1],\n         [1, 1, 1, 1],\n         [1, 1, 1, 1],\n         [1, 1, 1, 1]],\n\n        [[2, 2, 2, 2],\n         [2, 2, 2, 2],\n         [2, 2, 2, 2],\n         [2, 2, 2, 2]],\n\n        [[3, 3, 3, 3],\n         [3, 3, 3, 3],\n         [3, 3, 3, 3],\n         [3, 3, 3, 3]]])"
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[[[1, 1, 1, 1],\n          [1, 1, 1, 1],\n          [1, 1, 1, 1],\n          [1, 1, 1, 1]]],\n\n\n        [[[2, 2, 2, 2],\n          [2, 2, 2, 2],\n          [2, 2, 2, 2],\n          [2, 2, 2, 2]]],\n\n\n        [[[3, 3, 3, 3],\n          [3, 3, 3, 3],\n          [3, 3, 3, 3],\n          [3, 3, 3, 3]]]])"
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "source": [
    "a = a.reshape(3,1,4,4)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the shape functions has allowed the three rank 2 tensors to be concatenated into a rank 3 tensors\n",
    "\n",
    "the batch size is 3, the height is 4 and the width is 4\n",
    "\n",
    "a CNN expects an implicitly stated colour depth therefore it is reshaped to include a 1 under that field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the first dimension image\n",
    "\n",
    "the second dimension colour channel\n",
    "\n",
    "the third dimension row of pixels\n",
    "\n",
    "the last dimension pixel value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n        [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]])"
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "source": [
    "a.flatten(start_dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([3, 16])"
     },
     "metadata": {},
     "execution_count": 64
    }
   ],
   "source": [
    "a.flatten(start_dim=1).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python37664bitd0b078c581744c51ba9098f8d851824d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}